{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "This code is part of the SIPN2 project focused on improving sub-seasonal to seasonal predictions of Arctic Sea Ice. \n",
    "If you use this code for a publication or presentation, please cite the reference in the README.md on the\n",
    "main page (https://github.com/NicWayand/ESIO). \n",
    "\n",
    "Questions or comments should be addressed to nicway@uw.edu\n",
    "\n",
    "Copyright (c) 2018 Nic Wayand\n",
    "\n",
    "GNU General Public License v3.0\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "Plot forecast maps with all available models.\n",
    "'''\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "import numpy as np\n",
    "import timeit\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import struct\n",
    "import os\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import glob\n",
    "import datetime\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import seaborn as sns\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from esio import EsioData as ed\n",
    "from esio import ice_plot\n",
    "from esio import import_data\n",
    "\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "\n",
    "\n",
    "# General plotting settings\n",
    "sns.set_style('ticks')\n",
    "sns.set_context(\"talk\", font_scale=.8, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = ed.EsioData.load()\n",
    "# Directories\n",
    "all_models=['rasmesrl']\n",
    "runType='forecast'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Info\n",
    "runType = 'forecast'\n",
    "variables = ['sic']\n",
    "metrics_all = {'sic':['SIP']}\n",
    "# Some models not to include\n",
    "MME_NO = ['hcmr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target time range\n",
    "valid_start = np.datetime64('2018-09-01')\n",
    "valid_end = np.datetime64('2018-09-30')\n",
    "\n",
    "# SIO Report Year_Month\n",
    "cyear = '2018'\n",
    "# cmonth = 'June'\n",
    "cmonth = 'July'\n",
    "\n",
    "# Models that create an Ensemble using different init days\n",
    "it_target_size = {'usnavysipn':10, 'ukmetofficesipn':21} # Define the number of past days to use TODO: assumes daily inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom mod names\n",
    "custom_names = {'usnavysipn':'NESM','gfdlsipn':'GFDL/NOAA','noaasipn':'NOAA CPC','uclsipn':'UCL','ukmetofficesipn':'Met Office','ecmwfsipn':'ECMWF-c3s'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to plot\n",
    "models_2_plot = list(E.model.keys())\n",
    "models_2_plot = [x for x in models_2_plot if np.any(x not in ['piomas','MME','modcansipns_3','modcansipns_4','ecmwfsipn']) ] # remove some models\n",
    "models_2_plot = [x for x in models_2_plot if E.icePredicted[x]] # Only predictive models\n",
    "models_2_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stero_grid_file = E.obs['NSIDC_0051']['grid']\n",
    "obs_grid = import_data.load_grid_info(stero_grid_file, model='NSIDC')\n",
    "# Ensure latitude is within bounds (-90 to 90)\n",
    "# Have to do this because grid file has 90.000001\n",
    "obs_grid['lat_b'] = obs_grid.lat_b.where(obs_grid.lat_b < 90, other = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regridding Options\n",
    "method='nearest_s2d' # ['bilinear', 'conservative', 'nearest_s2d', 'nearest_d2s', 'patch']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in User submited SIP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sip = [] # Dictionary to store user submitted (regridded) SIP data\n",
    "r_yr_mon = cyear+'_'+cmonth\n",
    "\n",
    "import calendar\n",
    "mon_2_int = {v: k for k,v in enumerate(calendar.month_name)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### npssipn (RASM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod = 'RASM'\n",
    "if r_yr_mon=='2018_June':\n",
    "    sip_f = '/home/disk/sipn/upload/npssipn/forecast/Forecast/RASM_Sep2018_Junreportdata.nc'\n",
    "elif r_yr_mon=='2018_July':\n",
    "    sip_f = '/home/disk/sipn/upload/npssipn/forecast/Forecast/RASM_Sep2018_Julyreportdata.nc'\n",
    "else:\n",
    "    raise ValueError(r_yr_mon,\"not found, add sip_f path.\")\n",
    "\n",
    "# Open\n",
    "ds_user = xr.open_dataset(sip_f)\n",
    "sip_f = None\n",
    "\n",
    "# Regrid/format to sipn\n",
    "ds_user.rename({'lat':'nj', 'long':'ni','longitude':'lon','latitude':'lat'}, inplace=True);\n",
    "ds_user.set_coords(['lat','lon'], inplace=True)\n",
    "# Select SIP\n",
    "da_in = ds_user.SIP_ID\n",
    "mask = ds_user.Grid_Area.notnull()\n",
    "da_in = da_in.where(mask)\n",
    "\n",
    "# Calculate regridding matrix\n",
    "regridder = xe.Regridder(da_in, obs_grid, method, periodic=False)\n",
    "# Regrid \n",
    "da_out = regridder(da_in)\n",
    "# Remove weight file\n",
    "regridder.clean_weight_file() \n",
    "# da_in.plot()\n",
    "# plt.figure()\n",
    "# da_out.plot()\n",
    "\n",
    "# Store in dict of user submited SIP\n",
    "da_out.coords['model'] = cmod\n",
    "user_sip.append(da_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cansips (Mod CanSIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod = 'Mod CanSIPS'\n",
    "\n",
    "if r_yr_mon=='2018_June':\n",
    "    sip_f = '/home/disk/sipn/upload/ecsipn/Modified_CanSIPS_Sep2018_JuneInit_SIP.nc'\n",
    "elif r_yr_mon=='2018_July':\n",
    "    sip_f='/home/disk/sipn/upload/ecsipn/July_2018/Modified_CanSIPS_Sep2018_JulyInit_SIP.nc'\n",
    "else:\n",
    "    raise ValueError(r_yr_mon,\"not found, add sip_f path.\")   \n",
    "    \n",
    "ds_user = xr.open_dataset(sip_f)\n",
    "sip_f = None\n",
    "ds_user.rename({'lat':'nj', 'lon':'ni','longitude':'lon','latitude':'lat'}, inplace=True);\n",
    "ds_user.set_coords(['lat','lon'], inplace=True)\n",
    "# Select SIP\n",
    "da_in = ds_user.sip.isel(time=0)\n",
    "\n",
    "# Calculate regridding matrix\n",
    "regridder = xe.Regridder(da_in, obs_grid, method, periodic=False)\n",
    "# Regrid \n",
    "da_out = regridder(da_in)\n",
    "# Remove weight file\n",
    "regridder.clean_weight_file() \n",
    "da_in.plot()\n",
    "plt.figure()\n",
    "da_out.plot()\n",
    "# Store in dict of user submited SIP\n",
    "da_out.coords['model'] = cmod\n",
    "user_sip.append(da_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nrlsipn (NESM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmod = 'NESM'\n",
    "\n",
    "# if r_yr_mon=='2018_June':\n",
    "#     sip_f = '/home/disk/sipn/nicway/data/model/usnavysipn/forecast/metrics_from_nrl/NESM_Sep2018_Maydata_SIP_common.nc'\n",
    "# elif r_yr_mon=='2018_July':\n",
    "#     sip_f=''\n",
    "# else:\n",
    "#     raise ValueError(r_yr_mon,\"not found, add sip_f path.\")  \n",
    "\n",
    "# ds_user = xr.open_dataset(sip_f)\n",
    "# sip_f = None\n",
    "# ds_user.rename({'Longitude':'lon','Latitude':'lat'}, inplace=True);\n",
    "# # Select SIP\n",
    "# da_in = ds_user.SIP.isel(MT=0)\n",
    "# da_in = da_in / 100 # scale to 0-1\n",
    "\n",
    "# # Calculate regridding matrix\n",
    "# regridder = xe.Regridder(da_in, obs_grid, method, periodic=False)\n",
    "# # Regrid \n",
    "# da_out = regridder(da_in)\n",
    "# # Remove weight file\n",
    "# regridder.clean_weight_file() \n",
    "# # da_in.plot()\n",
    "# # plt.figure()\n",
    "# # da_out.plot()\n",
    "# # Store in dict of user submited SIP\n",
    "# da_out.coords['model'] = cmod\n",
    "# print(\"Not adding User submited NESM here, Joe wanted us to use our own calculated one\")\n",
    "# #user_sip.append(da_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test plot\n",
    "# da_in.plot()\n",
    "# plt.figure()\n",
    "# da_out.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sean H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod = 'BBGLM'\n",
    "\n",
    "if r_yr_mon=='2018_June':\n",
    "    sip_f = '/home/disk/sipn/upload/seansipn/forecast/2018_it_June_vt_Sept.nc'\n",
    "elif r_yr_mon=='2018_July':\n",
    "    sip_f='/home/disk/sipn/upload/seansipn/forecast/July/2018_it_July_vt_Sept.nc'\n",
    "else:\n",
    "    raise ValueError(r_yr_mon,\"not found, add sip_f path.\")  \n",
    "\n",
    "ds_user = xr.open_dataset(sip_f)\n",
    "da_in = ds_user.mean(dim='valid_time').SIP\n",
    "\n",
    "# Calculate regridding matrix\n",
    "regridder = xe.Regridder(da_in, obs_grid, method, periodic=False)\n",
    "# Regrid \n",
    "da_out = regridder(da_in)\n",
    "# Remove weight file\n",
    "regridder.clean_weight_file() \n",
    "da_in.plot()\n",
    "plt.figure()\n",
    "da_out.plot()\n",
    "# Store in dict of user submited SIP\n",
    "da_out.coords['model'] = cmod\n",
    "user_sip.append(da_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xioajun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod = 'Lamont\\n(Yuan et al.)'\n",
    "\n",
    "if r_yr_mon=='2018_June':\n",
    "    sip_f = None # no forecast given\n",
    "elif r_yr_mon=='2018_July':\n",
    "    sip_f='/home/disk/sipn/nicway/data/model/Xioajun/forecast/native/Xiaojun_Yuan_Yuan_Sep2018_Julydata_SIC_Arctic_native.nc'\n",
    "else:\n",
    "    raise ValueError(r_yr_mon,\"not found, add sip_f path.\")  \n",
    "\n",
    "if sip_f:\n",
    "    ds_user = xr.open_dataset(sip_f)\n",
    "    \n",
    "    da_in = ds_user.rename({'X':'lon','Y':'lat'}).isel(T=0).ice\n",
    "    da_in = da_in/100\n",
    "    # SIC to SIP\n",
    "    da_in = (da_in>0.15).where(da_in.notnull())\n",
    "    # Calculate regridding matrix\n",
    "    regridder = xe.Regridder(da_in, obs_grid, method, periodic=True)\n",
    "    # Regrid \n",
    "    da_out = regridder(da_in)\n",
    "    # Remove weight file\n",
    "    regridder.clean_weight_file() \n",
    "    da_in.plot()\n",
    "    plt.figure()\n",
    "    da_out.plot()\n",
    "    # Store in dict of user submited SIP\n",
    "    da_out.coords['model'] = cmod\n",
    "    user_sip.append(da_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA GMAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmod = 'GMAO'\n",
    "\n",
    "if r_yr_mon=='2018_June':\n",
    "    sip_f = None # no forecast given\n",
    "elif r_yr_mon=='2018_July':\n",
    "    sip_f='/home/disk/sipn/nicway/data/model/gmao/gmao_Sep2018_Julydata_SIP_thatssmigrid.nc4'\n",
    "else:\n",
    "    raise ValueError(r_yr_mon,\"not found, add sip_f path.\")  \n",
    "\n",
    "if sip_f:\n",
    "    ds_user = xr.open_dataset(sip_f)\n",
    "    \n",
    "    ds_user = ds_user.set_coords(['LAT','LON'])\n",
    "    \n",
    "    da_in = ds_user.rename({'LON':'lon','LAT':'lat','SIP':'sip'}).sip\n",
    "    \n",
    "    da_in = da_in/100 # 100% to 0-1\n",
    "\n",
    "    # Calculate regridding matrix\n",
    "    regridder = xe.Regridder(da_in, obs_grid, method, periodic=True)\n",
    "    # Regrid \n",
    "    da_out = regridder(da_in)\n",
    "    # Remove weight file\n",
    "    regridder.clean_weight_file() \n",
    "    da_in.plot()\n",
    "    plt.figure()\n",
    "    da_out.plot()\n",
    "    # Store in dict of user submited SIP\n",
    "    da_out.coords['model'] = cmod\n",
    "    user_sip.append(da_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_SIP = xr.concat(user_sip, dim='model')\n",
    "usr_SIP = usr_SIP.rename({'nj':'x', 'ni':'y'})\n",
    "usr_SIP.name = 'SIP'\n",
    "usr_SIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through SIPN SIC data and plot those models that have forecasts through target month\n",
    "- Use most recent init_time (if multiple)\n",
    "- Use monthly sept mean SIC for each ensemble member to calculate SIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the last init day as the 11th of the current month's report (i.e. June would be the 11th of June)\n",
    "last_init_day = np.datetime64(datetime.datetime(int(cyear),mon_2_int[cmonth],11))\n",
    "# Define the earliest init day as 1 year before last_init_day ( some models init on 1st of month (i.e. UCL))\n",
    "first_init_day = last_init_day-np.timedelta64(365,'D')\n",
    "print(\"Looking for init times between\",first_init_day,\"and\",last_init_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cvar in variables:\n",
    "    \n",
    "    # Define fig dir and make if doesn't exist\n",
    "    fig_dir = os.path.join(E.fig_dir, 'model', 'SIO_Reports', cyear, cmonth)\n",
    "    if not os.path.exists(fig_dir):\n",
    "        os.makedirs(fig_dir)\n",
    "       \n",
    "    # Loop through variable of interest + any metrics (i.e. SIP) based on that\n",
    "    for metric in metrics_all[cvar]:\n",
    "\n",
    "        MME_list = []      \n",
    "    \n",
    "        # For each model\n",
    "        for (i, cmod) in enumerate(models_2_plot):\n",
    "            print(\"\")\n",
    "            print(cmod)\n",
    "\n",
    "            # Load in Model\n",
    "            model_forecast = os.path.join(E.model[cmod][runType]['sipn_nc'], '*.nc') \n",
    "\n",
    "            # Check we have files \n",
    "            files = glob.glob(model_forecast)\n",
    "            if not files:\n",
    "                #print(\"Skipping model\", cmod, \"no forecast files found.\")\n",
    "                continue # Skip this model\n",
    "\n",
    "            start_time = timeit.default_timer()\n",
    "            ds_model = xr.open_mfdataset(model_forecast, \n",
    "                        chunks={'fore_time': 1, 'init_time': 1, 'nj': 304, 'ni': 448}, \n",
    "                                         concat_dim='init_time', autoclose=True, parallel=True)\n",
    "            ds_model.rename({'nj':'x', 'ni':'y'}, inplace=True)\n",
    "            print(\"    Loading took  \", (timeit.default_timer() - start_time)/60, \" minutes.\")\n",
    "\n",
    "            # Select var of interest (if available)\n",
    "            if cvar in ds_model.variables:\n",
    "#                     print('found ',cvar)\n",
    "                ds_model = ds_model[cvar]\n",
    "            else:\n",
    "                print('    cvar not found.')\n",
    "                continue\n",
    "                  \n",
    "            # Select init times\n",
    "            \n",
    "            # Use lagged ensemble\n",
    "            if cmod in list(it_target_size.keys()): # Uses a lagged ensemble... so grab all inits and make them ensembles\n",
    "                \n",
    "                # NESM (Joe) wants us to use the past months inits (June for July report)\n",
    "                if cmod == 'usnavysipn':\n",
    "                    # Replace last_init_day inline below (note the \"-1\" meaning last month)\n",
    "                    ds_model = ds_model.sel(init_time=slice(first_init_day,  np.datetime64(datetime.datetime(int(cyear),mon_2_int[cmonth] - 1, 11))  )) # First get all time between start and stop (up to and including the 10th)\n",
    "                else:\n",
    "                    ds_model = ds_model.sel(init_time=slice(first_init_day,last_init_day)) # First get all time between start and stop (up to and including the 10th)\n",
    "                \n",
    "                if ds_model.init_time.size==0:\n",
    "                    print(\"    No init_times found in requested start range\",first_init_day,\"to\",last_init_day,\". So skipping...\")\n",
    "                    continue\n",
    "                    \n",
    "                print(\"    Init times used are\",ds_model.init_time[-1*it_target_size[cmod]:].values)    \n",
    "                \n",
    "                ds_model = ds_model.sel(init_time=ds_model.init_time[-1*it_target_size[cmod]:]) # Get nearest date to 10th\n",
    "                avg_init_time = ds_model.init_time.astype('int').median().astype('datetime64[ns]')\n",
    "                ds_model = ds_model.stack(hybrid_ensemble=('ensemble', 'init_time')).reset_index('hybrid_ensemble')\n",
    "                ds_model.coords['hybrid_ensemble'] = np.arange(1,ds_model.hybrid_ensemble.size+1,1)\n",
    "                ds_model = ds_model.drop(['ensemble','init_time'])\n",
    "                ds_model.coords['init_time'] = avg_init_time\n",
    "                ds_model = ds_model.rename({'hybrid_ensemble':'ensemble'})\n",
    "                print(ds_model)\n",
    "\n",
    "            # Normal Ensemble\n",
    "            else:\n",
    "                # Find init time closest and earlier to the 10th of the month\n",
    "                ds_model = ds_model.sel(init_time=slice(first_init_day,last_init_day)) # First get all time between start and stop (up to and including the 10th)\n",
    "                if ds_model.init_time.size==0:\n",
    "                    print(\"    No init_times found in requested start range\",first_init_day,\"to\",last_init_day,\". So skipping...\")\n",
    "                    continue\n",
    "                ds_model = ds_model.sel(init_time=last_init_day, method='nearest') # Get nearest date to 10th\n",
    "            print(\"    Init time used is\",ds_model.init_time.values)\n",
    "                  \n",
    "            # Get Valid time\n",
    "            ds_model = import_data.get_valid_time(ds_model.expand_dims('init_time'))\n",
    "                  \n",
    "            # Check if we have any valid times in range of target dates\n",
    "            ds_model = ds_model.where((ds_model.valid_time>=valid_start) & (ds_model.valid_time<=valid_end), drop=True) \n",
    "            if ds_model.fore_time.size == 0:\n",
    "                print(\"    no fore_time found for target period.\")\n",
    "                continue\n",
    "                 \n",
    "            # Average over for_time\n",
    "            ds_model = ds_model.mean(dim='fore_time')\n",
    "            \n",
    "            start_time = timeit.default_timer()\n",
    "#                 print(\"Found data for model \", cmod, \". Plotting...\")    \n",
    "            if metric=='mean': # Calc ensemble mean\n",
    "                ds_model = ds_model.mean(dim='ensemble')\n",
    "            elif metric=='SIP': # Calc probability\n",
    "                ok_ens = ((ds_model.notnull().sum(dim='x').sum(dim='y'))>0) # select ensemble members with any data\n",
    "                ds_model = ((ds_model.where(ok_ens, drop=True)>=0.15) ).mean(dim='ensemble').where(ds_model.isel(ensemble=0).notnull())\n",
    "            elif metric=='anomaly': # Calc anomaly in reference to mean observed 1980-2010\n",
    "                ds_model = ds_model.mean(dim='ensemble') - da_obs_mean\n",
    "                # Add back lat/long (get dropped because of round off differences)\n",
    "                ds_model['lat'] = da_obs_mean.lat\n",
    "                ds_model['lon'] = da_obs_mean.lon\n",
    "            else:\n",
    "                raise ValueError('metric not implemented')\n",
    "            print(\"    Calc metric took  \", (timeit.default_timer() - start_time)/60, \" minutes.\")\n",
    "\n",
    "            # Build MME\n",
    "            if 'ensemble' in ds_model:\n",
    "                ds_model = ds_model.drop('ensemble')\n",
    "            if cmod not in MME_NO: # Exclude some models (bad) from MME\n",
    "                ds_model.coords['model'] = cmod\n",
    "                MME_list.append(ds_model)\n",
    "                print('    Added ',cmod,' to MME.')\n",
    "\n",
    "# Done with current it\n",
    "print(\"Took \", (timeit.default_timer() - start_time)/60, \" minutes.\")\n",
    "\n",
    "# Concat over all models\n",
    "ds_MME = xr.concat(MME_list, dim='model')\n",
    "ds_MME.name = 'SIP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take mean over init_time (different models init different times. mean doesn't change values)\n",
    "model_inits = ds_MME.init_time # Save init_times\n",
    "models_list = ds_MME.model\n",
    "ds_MME = ds_MME.mean(dim='init_time')\n",
    "ds_MME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge user SIP with SPIN SIP\n",
    "ds_SIP_All = xr.concat([ds_MME,usr_SIP], dim='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into memory\n",
    "ds_SIP_All.load()\n",
    "# Save to disk\n",
    "ds_SIP_All.to_netcdf('/home/disk/sipn/nicway/data/model/SIO/'+cyear+'/'+cmonth+'/SIP.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_MME_avg = ds_SIP_All.mean(dim='model')\n",
    "ds_MME_std = ds_SIP_All.std(dim='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting info\n",
    "if cvar=='sic':\n",
    "    if metric=='mean':\n",
    "        cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"Blues_r\", 10))\n",
    "        cmap_c.set_bad(color = 'lightgrey')\n",
    "        c_label = 'Sea Ice Concentration (-)'\n",
    "        c_vmin = 0\n",
    "        c_vmax = 1\n",
    "    elif metric=='SIP':\n",
    "        cmap_c = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"orange\",\"red\",\"#990000\"], N=10)\n",
    "        #cmap_c = plt.get_cmap('jet') \n",
    "        cmap_c.set_bad(color = 'lightgrey')\n",
    "        c_label = 'Sea Ice Probability (-)'\n",
    "        c_vmin = 0\n",
    "        c_vmax = 1\n",
    "    elif metric=='anomaly':\n",
    "#                         cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"coolwarm\", 9))\n",
    "        cmap_c = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"white\",\"blue\"])\n",
    "        cmap_c.set_bad(color = 'lightgrey')\n",
    "        c_label = 'SIC Anomaly to 1980-2010 Mean'\n",
    "        c_vmin = -1\n",
    "        c_vmax = 1\n",
    "\n",
    "elif cvar=='hi':\n",
    "    if metric=='mean':\n",
    "        cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"Reds_r\", 10))\n",
    "        cmap_c.set_bad(color = 'lightgrey')\n",
    "        c_label = 'Sea Ice Thickness (m)'\n",
    "        c_vmin = 0\n",
    "        c_vmax = None\n",
    "else:\n",
    "    raise ValueError(\"cvar not found.\") \n",
    "\n",
    "\n",
    "    \n",
    "def add_subplot_title(cmod, custom_names, E, ax=None):\n",
    "    if cmod in custom_names:\n",
    "        ax.set_title(custom_names[cmod])\n",
    "    elif cmod in E.model.keys():\n",
    "        ax.set_title(E.model[cmod]['model_label'])\n",
    "    else:\n",
    "        ax.set_title(cmod)\n",
    "\n",
    "# New Plot\n",
    "central_extent = [-3850000*0.6, 3725000*0.6, -5325000*0.45, 5850000*0.45] # (x0, x1, y0, y1\n",
    "(f, axes) = ice_plot.multi_polar_axis(ncols=4, nrows=4, Nplots=20, extent=central_extent, central_longitude=0)\n",
    "\n",
    "for (i, cmod) in enumerate(ds_SIP_All.model.values):\n",
    "    print(cmod)\n",
    "    # Plot\n",
    "    add_subplot_title(cmod, custom_names, E, ax=axes[i])\n",
    "    p = ds_SIP_All.sel(model=cmod).plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                          transform=ccrs.PlateCarree(),\n",
    "                          add_colorbar=False,\n",
    "                          cmap=cmap_c,\n",
    "                          vmin=c_vmin, vmax=c_vmax)\n",
    "    add_subplot_title(cmod, custom_names, E, ax=axes[i])\n",
    "\n",
    "\n",
    "# MME Mean\n",
    "i = i + 1\n",
    "\n",
    "\n",
    "pmme = ds_MME_avg.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                  transform=ccrs.PlateCarree(),\n",
    "                                  add_colorbar=False, \n",
    "                                  cmap=cmap_c,vmin=c_vmin, vmax=c_vmax)\n",
    "axes[i].set_title('Mean')\n",
    "\n",
    "\n",
    "# MME Standard deviation\n",
    "i = i + 1\n",
    "\n",
    "\n",
    "pmme = ds_MME_std.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                  transform=ccrs.PlateCarree(),\n",
    "                                  add_colorbar=False, \n",
    "                                  cmap=cmap_c,vmin=c_vmin, vmax=c_vmax)\n",
    "axes[i].set_title('σ')\n",
    "    \n",
    "\n",
    "# Make pretty\n",
    "f.subplots_adjust(bottom=0.05)\n",
    "# cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "cbar_ax = f.add_axes([0.25, 0.001, .5, 0.04]) #  [left, bottom, width, height] w\n",
    "if p:\n",
    "    cbar = f.colorbar(p, cax=cbar_ax, label=c_label, orientation='horizontal')\n",
    "    if metric=='anomaly':\n",
    "        cbar.set_ticks(np.arange(-1,1.1,0.2))\n",
    "    else:\n",
    "        cbar.set_ticks(np.arange(0,1.1,0.2))\n",
    "\n",
    "# Save to file\n",
    "f_out = os.path.join(fig_dir,'panArctic_'+metric+'_'+runType+'_'+cyear+'_'+cmonth+'.png')\n",
    "f.savefig(f_out,bbox_inches='tight', dpi=300)\n",
    "f_out = os.path.join(fig_dir,'panArctic_'+metric+'_'+runType+'_'+cyear+'_'+cmonth+'_lowRES.png')\n",
    "f.savefig(f_out,bbox_inches='tight', dpi=90)\n",
    "print(\"saved \", f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare past mean forecasts\n",
    "ds_SIP_June = xr.open_mfdataset('/home/disk/sipn/nicway/data/model/SIO/'+'2018'+'/'+'June'+'/SIP.nc')\n",
    "ds_SIP_July = xr.open_mfdataset('/home/disk/sipn/nicway/data/model/SIO/'+'2018'+'/'+'July'+'/SIP.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "july_june_common_models = [x for x in ds_SIP_June.model.values if x not in ['awispin', 'nicosipn','ecmwfsipn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Plot\n",
    "central_extent = [-3850000*0.6, 3725000*0.6, -5325000*0.45, 5850000*0.45] # (x0, x1, y0, y1\n",
    "(f, axes) = ice_plot.multi_polar_axis(ncols=3, nrows=1, Nplots=20, extent=central_extent, central_longitude=0)\n",
    "\n",
    "i = 0\n",
    "pmme1 = ds_SIP_June.mean(dim='model').SIP.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                  transform=ccrs.PlateCarree(),\n",
    "                                  add_colorbar=False, \n",
    "                                  cmap=cmap_c,vmin=c_vmin, vmax=c_vmax)\n",
    "axes[i].set_title('June Multi\\nModel Mean')\n",
    "\n",
    "i = 1\n",
    "pmme2 = ds_SIP_July.mean(dim='model').SIP.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                  transform=ccrs.PlateCarree(),\n",
    "                                  add_colorbar=False, \n",
    "                                  cmap=cmap_c,vmin=c_vmin, vmax=c_vmax)\n",
    "axes[i].set_title('July Multi\\nModel Mean')\n",
    "\n",
    "\n",
    "i = 2\n",
    "cmap_diff = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"blue\",\"white\",\"red\",])\n",
    "cmap_diff.set_bad(color = 'lightgrey')\n",
    "pmme3 = (ds_SIP_July.sel(model=july_june_common_models).mean(dim='model')-ds_SIP_June.sel(model=july_june_common_models).mean(dim='model')).SIP.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                  transform=ccrs.PlateCarree(),\n",
    "                                  add_colorbar=False, \n",
    "                                  cmap=cmap_diff,vmin=-.2, vmax=.2)\n",
    "axes[i].set_title('Difference\\n(July - June)')\n",
    "\n",
    "\n",
    "f.subplots_adjust(bottom=0.02)\n",
    "cbar_ax = f.add_axes([0.25, 0.001, .5, 0.08]) #  [left, bottom, width, height] w\n",
    "cbar = f.colorbar(pmme2, cax=cbar_ax, label=c_label, orientation='horizontal')\n",
    "cbar.set_ticks(np.arange(0,1.1,0.2))\n",
    "\n",
    "cbar_ax_2 = f.add_axes([.93, 0.08, .025, 0.75]) #  [left, bottom, width, height] w\n",
    "cbar2 = f.colorbar(pmme3, cax=cbar_ax_2, label='SIP Change (-)', orientation='vertical')\n",
    "\n",
    "# Save to file\n",
    "f_out = os.path.join(fig_dir,'panArctic_'+metric+'_'+runType+'_'+cyear+'_July_June_diff.png')\n",
    "f.savefig(f_out,bbox_inches='tight', dpi=300)\n",
    "print(\"saved \", f_out)\n",
    "f_out = os.path.join(fig_dir,'panArctic_'+metric+'_'+runType+'_'+cyear+'_July_June_diff_lowRES.png')\n",
    "f.savefig(f_out,bbox_inches='tight', dpi=90)\n",
    "print(\"saved \", f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting info\n",
    "if cvar=='sic':\n",
    "    if metric=='mean':\n",
    "        cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"Blues_r\", 10))\n",
    "        cmap_c.set_bad(color = 'lightgrey')\n",
    "        c_label = 'Sea Ice Concentration (-)'\n",
    "        c_vmin = 0\n",
    "        c_vmax = 1\n",
    "    elif metric=='SIP':\n",
    "        cmap_c = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"orange\",\"red\",\"#990000\"], N=10)\n",
    "        #cmap_c = plt.get_cmap('jet') \n",
    "        cmap_c.set_bad(color = 'lightgrey')\n",
    "        c_label = 'Sea Ice Probability (-)'\n",
    "        c_vmin = 0\n",
    "        c_vmax = 1\n",
    "    elif metric=='anomaly':\n",
    "#                         cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"coolwarm\", 9))\n",
    "        cmap_c = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"white\",\"blue\"])\n",
    "        cmap_c.set_bad(color = 'lightgrey')\n",
    "        c_label = 'SIC Anomaly to 1980-2010 Mean'\n",
    "        c_vmin = -1\n",
    "        c_vmax = 1\n",
    "\n",
    "elif cvar=='hi':\n",
    "    if metric=='mean':\n",
    "        cmap_c = matplotlib.colors.ListedColormap(sns.color_palette(\"Reds_r\", 10))\n",
    "        cmap_c.set_bad(color = 'lightgrey')\n",
    "        c_label = 'Sea Ice Thickness (m)'\n",
    "        c_vmin = 0\n",
    "        c_vmax = None\n",
    "else:\n",
    "    raise ValueError(\"cvar not found.\") \n",
    "\n",
    "\n",
    "    \n",
    "def add_subplot_title(cmod, custom_names, E, ax=None):\n",
    "    if cmod in custom_names:\n",
    "        ax.set_title(custom_names[cmod])\n",
    "    elif cmod in E.model.keys():\n",
    "        ax.set_title(E.model[cmod]['model_label'])\n",
    "    else:\n",
    "        ax.set_title(cmod)\n",
    "\n",
    "# New Plot\n",
    "central_extent = [-3850000*0.6, 3725000*0.6, -5325000*0.45, 5850000*0.45] # (x0, x1, y0, y1\n",
    "(f, axes) = ice_plot.multi_polar_axis(ncols=4, nrows=4, Nplots=17, extent=central_extent, central_longitude=0)\n",
    "\n",
    "for (i, cmod) in enumerate(ds_SIP_All.model.values):\n",
    "    print(cmod)\n",
    "    # Plot\n",
    "    add_subplot_title(cmod, custom_names, E, ax=axes[i])\n",
    "    p = ds_SIP_All.sel(model=cmod).plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                          transform=ccrs.PlateCarree(),\n",
    "                          add_colorbar=False,\n",
    "                          cmap=cmap_c,\n",
    "                          vmin=c_vmin, vmax=c_vmax)\n",
    "    add_subplot_title(cmod, custom_names, E, ax=axes[i])\n",
    "\n",
    "\n",
    "# MME Mean\n",
    "i = i + 1\n",
    "# f.delaxes(axes[i])\n",
    "# i = i + 1\n",
    "# f.delaxes(axes[i])\n",
    "# i = i + 1\n",
    "\n",
    "pmme = ds_MME_avg.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                  transform=ccrs.PlateCarree(),\n",
    "                                  add_colorbar=False, \n",
    "                                  cmap=cmap_c,vmin=c_vmin, vmax=c_vmax)\n",
    "axes[i].set_title('Mean')\n",
    "\n",
    "\n",
    "# MME Standard deviation\n",
    "i = i + 1\n",
    "\n",
    "\n",
    "pmme = ds_MME_std.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                  transform=ccrs.PlateCarree(),\n",
    "                                  add_colorbar=False, \n",
    "                                  cmap=cmap_c,vmin=c_vmin, vmax=c_vmax)\n",
    "axes[i].set_title('σ')\n",
    "\n",
    "# Difference from last SIO\n",
    "i = i + 1\n",
    "cmap_diff = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"blue\",\"white\",\"red\",])\n",
    "cmap_diff.set_bad(color = 'lightgrey')\n",
    "pmme3 = (ds_SIP_July.sel(model=july_june_common_models).mean(dim='model')-ds_SIP_June.sel(model=july_june_common_models).mean(dim='model')).SIP.plot.pcolormesh(ax=axes[i], x='lon', y='lat', \n",
    "                                  transform=ccrs.PlateCarree(),\n",
    "                                  add_colorbar=False, \n",
    "                                  cmap=cmap_diff,vmin=-.2, vmax=.2)\n",
    "axes[i].set_title('Difference\\n(July - June)')\n",
    "    \n",
    "\n",
    "# Make pretty\n",
    "f.subplots_adjust(bottom=0.05)\n",
    "# cbar_ax = f.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "cbar_ax = f.add_axes([0.25, 0.001, .5, 0.04]) #  [left, bottom, width, height] w\n",
    "if p:\n",
    "    cbar = f.colorbar(p, cax=cbar_ax, label=c_label, orientation='horizontal')\n",
    "    if metric=='anomaly':\n",
    "        cbar.set_ticks(np.arange(-1,1.1,0.2))\n",
    "    else:\n",
    "        cbar.set_ticks(np.arange(0,1.1,0.2))\n",
    "        \n",
    "\n",
    "cbar_ax_2 = f.add_axes([0.93, 0.07, .025, .15]) #  [left, bottom, width, height] w\n",
    "cbar2 = f.colorbar(pmme3, cax=cbar_ax_2, label='SIP Change (-)', orientation='vertical')\n",
    "\n",
    "\n",
    "# Save to file\n",
    "f_out = os.path.join(fig_dir,'panArctic_'+metric+'_'+runType+'_'+cyear+'_'+cmonth+'_withDiff.png')\n",
    "f.savefig(f_out,bbox_inches='tight', dpi=300)\n",
    "f_out = os.path.join(fig_dir,'panArctic_'+metric+'_'+runType+'_'+cyear+'_'+cmonth+'_withDiff_lowRES.png')\n",
    "f.savefig(f_out,bbox_inches='tight', dpi=90)\n",
    "print(\"saved \", f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add check -- Compare June to July models (Make sure they are different! (unless they are supposed to be unchanged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.6.4 esio",
   "language": "python",
   "name": "esio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
